{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch5_the_mechanics_of_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_JBoBJa7JaOE",
        "_3x6JzXZKSlr",
        "5OOAmc8wKiZu",
        "yBp9KoqDd-zI"
      ],
      "authorship_tag": "ABX9TyNlBmeqduSOqGaW4IRYaMbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanocostantini/pytorch-book/blob/master/ch5_the_mechanics_of_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZncbEjuCgc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGokVCETHEEo",
        "colab_type": "text"
      },
      "source": [
        "## Regression problem\n",
        "\n",
        "We have a thermometer which doesn't show the units, so we do measurements in both this instrument and celsius to have estimate a model that would allow us to determine the units of our 'unlabelled' thermometer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JBoBJa7JaOE",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhPm4YqHH0ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Measurement in celsius\n",
        "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
        "t_c = torch.tensor(t_c) # convert to tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd-u8-BvIBPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Measurement in unknown unit\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_u = torch.tensor(t_u) # convert to tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ61tKtjIJaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e754ad3-70d0-4ddb-e536-e6541126d491"
      },
      "source": [
        "# There appear to be a linear relationship between the two measures\n",
        "plt.scatter(t_u, t_c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3b03632518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMWXPvTxJgnU",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlYWNnDwWB-6",
        "colab_type": "text"
      },
      "source": [
        "It generally makes sense to start from the simplest model, a linear model (like linear regression): `t_c = w * t_u + b`\n",
        "\n",
        "`w` and `b` are the `weight` and the `bias`, respectively. These are the parameters that we need to estimate.\n",
        "\n",
        "We estimate them by finding the values of `w` and `b` that minimise the model's error. But to do that, we need to a measure of the error, i.e. we need a **loss function** of which we want to find the minimum.\n",
        "\n",
        "This is the same as line fitting, but let's do it in pytorch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp0IZ6i_Vx3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First we need to define the model\n",
        "def model(t_u, w, b):\n",
        "  return w * t_u + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uL8Ho-8dzIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then we define the loss function\n",
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c) ** 2\n",
        "  return squared_diffs.mean() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0znGz9o3eWN0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "131553ae-a43d-40c8-8779-ca0f5c8350c1"
      },
      "source": [
        "# Finally we can initialise the value of the scalars (zero dimension tensors),\n",
        "# \"run\" the model and calculate the loss\n",
        "w = torch.ones(())\n",
        "b = torch.zeros(())\n",
        "\n",
        "t_p = model(t_u, w, b)\n",
        "print(t_p)\n",
        "\n",
        "loss = loss_fn(t_p, t_c)\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
            "        48.4000, 60.4000, 68.4000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1763.8846)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3x6JzXZKSlr",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFkX9RwYfmj1",
        "colab_type": "text"
      },
      "source": [
        "But how do we actually *estimate* `w` and `b` to make the loss as small as possible?\n",
        "\n",
        "We'll optimise the loss function with respect to the parameters using the *gradient descent* algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hucelqiMfCKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We define functions that calculate the rate of change around a particular point\n",
        "# for both w and b. These will tell us in which direction to change these parameters\n",
        "# to change the loss.\n",
        "\n",
        "# first define the increment around the point\n",
        "delta = 0.1\n",
        "\n",
        "# then the loss rate of change\n",
        "loss_rate_of_change_w = (loss_fn(model(t_u, w + delta, b), t_u) - loss_fn(model(t_u, w - delta, b), t_u)) / 2.0 * delta\n",
        "loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta), t_u) - loss_fn(model(t_u, w, b-delta), t_u)) / 2.0 * delta\n",
        "\n",
        "# to avoid big jumps we scale down the rate of change by a learning rate\n",
        "learning_rate = 1e-2\n",
        "\n",
        "# so that the values of w and b are updated as follows\n",
        "w = w - learning_rate * loss_rate_of_change_w\n",
        "b = b - learning_rate * loss_rate_of_change_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hysDeBeilGVS",
        "colab_type": "text"
      },
      "source": [
        "The above process is really not efficient and doesn't scale well. What we want instead is calculate the individual derivative of the loss function with respect to each parameter, and put them into a vector of derivatives, i.e. the *gradient*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSXjSgs92asv",
        "colab_type": "text"
      },
      "source": [
        "In this case we have two parameters so our gradient will have 2 derivatives, i.e.\n",
        "\n",
        "$$\n",
        " \\nabla_{w,b}L = \\left(\\frac{\\partial L}{\\partial w}, \\frac{\\partial L}{\\partial b}\\right) = \\left(\\frac{\\partial L}{\\partial m} \\frac{\\partial m}{\\partial w}, \\frac{\\partial L}{\\partial m} \\frac{\\partial m}{\\partial b}\\right)\n",
        " $$\n",
        "\n",
        " using the chain rule. Specifically the first term is the derivative of the loss with respect to the output of the model (i.e. the prediction), while the second term is the derivative of the model with respect to one of its parameter.\n",
        "\n",
        "In code we have the following: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx8_9eI62ZRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The partial derivative of the loss wrt the model output (t_p)\n",
        "def dloss_fn(t_p, t_c):\n",
        "  dsquared_diffs = 2 * (t_p - t_c) / t_p.size(0) # derivative of mean\n",
        "  return dsquared_diffs\n",
        "\n",
        "# The partial derivatives of the model wrt each of its parameters are:\n",
        "def dmodel_dw(t_u, w, b):\n",
        "  return t_u\n",
        "\n",
        "def dmodel_db(t_u, w, b):\n",
        "  return 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww8yWu4p7MUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we can define the gradience function\n",
        "def grad_fn(t_u, t_c, t_p, w, b):\n",
        "  dloss_dtp = dloss_fn(t_p, t_c)\n",
        "  dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
        "  dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
        "  return torch.stack([dloss_dw.sum(), dloss_db.sum()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFm8wk9u7OPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's now set up the training loop, which will have a forward pass\n",
        "# (calculation of prediction) and a backward pass (calculation of gradient). \n",
        "# The parameters will then be updated. This is repeated for as many epochs as\n",
        "# selected\n",
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c, print_output = False):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    w, b = params\n",
        "    # forward pass\n",
        "    t_p = model(t_u, w, b)\n",
        "    # backward pass\n",
        "    loss = loss_fn(t_p, t_c) # we calculate this just to show it, it's already taken into account in gradient function\n",
        "    grad = grad_fn(t_u, t_c, t_p, w, b)\n",
        "    # update parameters\n",
        "    params = params - learning_rate * grad\n",
        "    if print_output:\n",
        "      print(f'Epoch: {epoch}, Loss: {float(loss)}, Params: {params}, Grad: {grad}')\n",
        "  return params  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF2Q9Wrr_V8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "690ba305-c2b2-4268-e22e-73b91017b4bc"
      },
      "source": [
        "# And then we launch the training loop (100 epochs in this case)\n",
        "training_loop(\n",
        "    n_epochs = 15,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0, 0.0]), # random initialisation\n",
        "    t_u = t_u,\n",
        "    t_c = t_c,\n",
        "    print_output=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 1763.8846435546875, Params: tensor([-44.1730,  -0.8260]), Grad: tensor([4517.2969,   82.6000])\n",
            "Epoch: 2, Loss: 5802485.5, Params: tensor([2568.4014,   45.1637]), Grad: tensor([-261257.4219,   -4598.9712])\n",
            "Epoch: 3, Loss: 19408035840.0, Params: tensor([-148527.7344,   -2616.3933]), Grad: tensor([15109614.0000,   266155.7188])\n",
            "Epoch: 4, Loss: 64915909902336.0, Params: tensor([8589999.0000,  151310.8594]), Grad: tensor([-8.7385e+08, -1.5393e+07])\n",
            "Epoch: 5, Loss: 2.171305598207918e+17, Params: tensor([-4.9680e+08, -8.7510e+06]), Grad: tensor([5.0539e+10, 8.9023e+08])\n",
            "Epoch: 6, Loss: 7.262575831529281e+20, Params: tensor([2.8732e+10, 5.0610e+08]), Grad: tensor([-2.9229e+12, -5.1486e+10])\n",
            "Epoch: 7, Loss: 2.429183992928415e+24, Params: tensor([-1.6617e+12, -2.9270e+10]), Grad: tensor([1.6904e+14, 2.9776e+12])\n",
            "Epoch: 8, Loss: 8.125126681682404e+27, Params: tensor([9.6102e+13, 1.6928e+12]), Grad: tensor([-9.7764e+15, -1.7221e+14])\n",
            "Epoch: 9, Loss: 2.7176891792249148e+31, Params: tensor([-5.5580e+15, -9.7903e+13]), Grad: tensor([5.6541e+17, 9.9596e+15])\n",
            "Epoch: 10, Loss: 9.090115470662065e+34, Params: tensor([3.2144e+17, 5.6621e+15]), Grad: tensor([-3.2700e+19, -5.7600e+17])\n",
            "Epoch: 11, Loss: inf, Params: tensor([-1.8590e+19, -3.2746e+17]), Grad: tensor([1.8912e+21, 3.3313e+19])\n",
            "Epoch: 12, Loss: inf, Params: tensor([1.0752e+21, 1.8939e+19]), Grad: tensor([-1.0937e+23, -1.9266e+21])\n",
            "Epoch: 13, Loss: inf, Params: tensor([-6.2181e+22, -1.0953e+21]), Grad: tensor([6.3256e+24, 1.1142e+23])\n",
            "Epoch: 14, Loss: inf, Params: tensor([3.5962e+24, 6.3346e+22]), Grad: tensor([-3.6584e+26, -6.4441e+24])\n",
            "Epoch: 15, Loss: inf, Params: tensor([-2.0798e+26, -3.6636e+24]), Grad: tensor([2.1158e+28, 3.7269e+26])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.0798e+26, -3.6636e+24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-PtCAswB-nH",
        "colab_type": "text"
      },
      "source": [
        "The loss exploded, probably due to parameter updates that are are too large. Look how the value of the parameters oscillates more and more. It's a *diverging* optimisation process, exactly the opposite of what we want.\n",
        "\n",
        "The first thing to try is to reduce the learning rate, we try `1e-4`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC9Lwtvb_t3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7e7483-31d1-40e0-bafb-ef9632d0b4cb"
      },
      "source": [
        "training_loop(\n",
        "    n_epochs = 15,\n",
        "    learning_rate = 1e-4,\n",
        "    params = torch.tensor([1.0, 0.0]), # random initialisation\n",
        "    t_u = t_u,\n",
        "    t_c = t_c,\n",
        "    print_output = True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 1763.8846435546875, Params: tensor([ 0.5483, -0.0083]), Grad: tensor([4517.2969,   82.6000])\n",
            "Epoch: 2, Loss: 323.0905456542969, Params: tensor([ 0.3623, -0.0118]), Grad: tensor([1859.5493,   35.7843])\n",
            "Epoch: 3, Loss: 78.92963409423828, Params: tensor([ 0.2858, -0.0135]), Grad: tensor([765.4667,  16.5122])\n",
            "Epoch: 4, Loss: 37.5528450012207, Params: tensor([ 0.2543, -0.0143]), Grad: tensor([315.0790,   8.5787])\n",
            "Epoch: 5, Loss: 30.540285110473633, Params: tensor([ 0.2413, -0.0149]), Grad: tensor([129.6733,   5.3127])\n",
            "Epoch: 6, Loss: 29.351152420043945, Params: tensor([ 0.2360, -0.0153]), Grad: tensor([53.3495,  3.9682])\n",
            "Epoch: 7, Loss: 29.148881912231445, Params: tensor([ 0.2338, -0.0156]), Grad: tensor([21.9303,  3.4148])\n",
            "Epoch: 8, Loss: 29.113847732543945, Params: tensor([ 0.2329, -0.0159]), Grad: tensor([8.9964, 3.1869])\n",
            "Epoch: 9, Loss: 29.107145309448242, Params: tensor([ 0.2325, -0.0162]), Grad: tensor([3.6721, 3.0930])\n",
            "Epoch: 10, Loss: 29.105241775512695, Params: tensor([ 0.2324, -0.0166]), Grad: tensor([1.4803, 3.0544])\n",
            "Epoch: 11, Loss: 29.104167938232422, Params: tensor([ 0.2323, -0.0169]), Grad: tensor([0.5781, 3.0384])\n",
            "Epoch: 12, Loss: 29.103221893310547, Params: tensor([ 0.2323, -0.0172]), Grad: tensor([0.2066, 3.0318])\n",
            "Epoch: 13, Loss: 29.102296829223633, Params: tensor([ 0.2323, -0.0175]), Grad: tensor([0.0537, 3.0291])\n",
            "Epoch: 14, Loss: 29.10137939453125, Params: tensor([ 0.2323, -0.0178]), Grad: tensor([-0.0093,  3.0279])\n",
            "Epoch: 15, Loss: 29.1004695892334, Params: tensor([ 0.2323, -0.0181]), Grad: tensor([-0.0353,  3.0274])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2323, -0.0181])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIKL4iz0Cqbe",
        "colab_type": "text"
      },
      "source": [
        "This worked better, we can see that soon the value of the loss stabilises and the value of the parameters does not change that much. \n",
        "\n",
        "However, after a while the loss stabilises. There is a potential other problem here, the gradient. We see in Epoch 1 that the gradient for `w` is much bigger than the gradient for `b`. As the two parameters are in *differently scaled spaces*, it's unlikely that the learning rate will be optimal for both. So the solution is to scale the inputs. We can do this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AektSwEsCm22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_un = 0.1 * t_u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlDiX4xKFBmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6375afe4-4d5d-4784-e38e-489f01ac0a13"
      },
      "source": [
        "# then we re-run the training loop\n",
        "training_loop(\n",
        "    n_epochs = 15,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0, 0.0]), # random initialisation\n",
        "    t_u = t_un,\n",
        "    t_c = t_c,\n",
        "    print_output = True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 80.36434173583984, Params: tensor([1.7761, 0.1064]), Grad: tensor([-77.6140, -10.6400])\n",
            "Epoch: 2, Loss: 37.57491683959961, Params: tensor([2.0848, 0.1303]), Grad: tensor([-30.8623,  -2.3864])\n",
            "Epoch: 3, Loss: 30.871076583862305, Params: tensor([2.2094, 0.1217]), Grad: tensor([-12.4631,   0.8587])\n",
            "Epoch: 4, Loss: 29.756193161010742, Params: tensor([2.2616, 0.1004]), Grad: tensor([-5.2218,  2.1327])\n",
            "Epoch: 5, Loss: 29.50714874267578, Params: tensor([2.2853, 0.0740]), Grad: tensor([-2.3715,  2.6310])\n",
            "Epoch: 6, Loss: 29.392457962036133, Params: tensor([2.2978, 0.0458]), Grad: tensor([-1.2492,  2.8241])\n",
            "Epoch: 7, Loss: 29.298828125, Params: tensor([2.3059, 0.0168]), Grad: tensor([-0.8071,  2.8970])\n",
            "Epoch: 8, Loss: 29.208717346191406, Params: tensor([ 2.3122, -0.0124]), Grad: tensor([-0.6325,  2.9227])\n",
            "Epoch: 9, Loss: 29.119417190551758, Params: tensor([ 2.3178, -0.0417]), Grad: tensor([-0.5633,  2.9298])\n",
            "Epoch: 10, Loss: 29.030487060546875, Params: tensor([ 2.3232, -0.0710]), Grad: tensor([-0.5355,  2.9295])\n",
            "Epoch: 11, Loss: 28.941875457763672, Params: tensor([ 2.3284, -0.1003]), Grad: tensor([-0.5240,  2.9264])\n",
            "Epoch: 12, Loss: 28.853565216064453, Params: tensor([ 2.3336, -0.1295]), Grad: tensor([-0.5190,  2.9222])\n",
            "Epoch: 13, Loss: 28.76555633544922, Params: tensor([ 2.3388, -0.1587]), Grad: tensor([-0.5165,  2.9175])\n",
            "Epoch: 14, Loss: 28.6778507232666, Params: tensor([ 2.3439, -0.1878]), Grad: tensor([-0.5150,  2.9126])\n",
            "Epoch: 15, Loss: 28.590431213378906, Params: tensor([ 2.3491, -0.2169]), Grad: tensor([-0.5138,  2.9077])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.3491, -0.2169])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esma89jxFA5y",
        "colab_type": "text"
      },
      "source": [
        "We can see that even with a learning rate of `1e-2`, the optimisation no longer explodes. Finally, let's run the model for 5,000 epochs and see the value of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YgJBAtWE_R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0, 0.0]), # random initialisation\n",
        "    t_u = t_un,\n",
        "    t_c = t_c,\n",
        "    print_output = False\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZkvPLe0H4uF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d88ef7ff-e728-4e7d-a8c8-55dd374db4c5"
      },
      "source": [
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGiOyifFH--F",
        "colab_type": "text"
      },
      "source": [
        "These values look familiar, as they are (very close to the value of) the parameters to go from Celsius to Fahrenheit degrees (the missing unit from the thermometers)\n",
        "\n",
        "We can visualise that this is a good fit, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppGxZ3HZH5sS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108c52ea-7119-4990-c538-a564a6806422"
      },
      "source": [
        "t_p = model(t_un, *params) # argument unpacking\n",
        "\n",
        "fig = plt.figure(dpi=300)\n",
        "plt.xlabel(\"F\")\n",
        "plt.ylabel(\"C\")\n",
        "plt.plot(t_u, t_p)\n",
        "plt.plot(t_u, t_c, 'o')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3b0121fd68>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x1200 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OOAmc8wKiZu",
        "colab_type": "text"
      },
      "source": [
        "## Using PyTorch's autograd (automatic gradient calculation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLForWasKOXb",
        "colab_type": "text"
      },
      "source": [
        "PyTorch tensors can remember where they come from, in terms of the operations and parent tensors that originated them, and they can automatically provide the chain of derivatives of such operations with respect to their inputs. \n",
        "\n",
        "This means we won't need to derive our model by hand: given a forward expression, no matter how nested, PyTorch will automatically provide the gradient of that expression with respect to its input parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSBDEixmJnUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7eab230d-941d-4acd-ea3f-9df2a8546d28"
      },
      "source": [
        "# We can use autograd by passing the 'requires_grad=True' parameter when we \n",
        "# initialise the parameters\n",
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "\n",
        "loss = loss_fn(model(t_u, *params), t_c)\n",
        "loss.backward() # this triggers the calculation of the gradient\n",
        "\n",
        "# and we can see the gradient here:\n",
        "params.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4517.2969,   82.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxWKMpkNTGjm",
        "colab_type": "text"
      },
      "source": [
        "** NOTE: ** PyTorch accumulates the value of derivatives in the grad attributes. this could lead to an incorrect value of the gradient if `backward` was called earlier.  \n",
        "\n",
        "At each iteration, We need to zero the gradient explicitly after using it for parameter updates, as follows:\n",
        "```\n",
        "if params.grad is not None:\n",
        "  params.grad.zero_()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD46uvWSSeC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can now re-define the training loop using autograd\n",
        "def training_loop_auto(n_epochs, learning_rate, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "    loss.backward() # this means that params.grad will now be calculated\n",
        "\n",
        "    with torch.no_grad(): # to prevent Pytorch from adding edges to the forward graph\n",
        "      params -= params.grad * learning_rate\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f'Epoch: {epoch}, Loss: {loss}, Grad: {params.grad}, Params: {params}')\n",
        "    \n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLxTBHffZoir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "a66a302c-0990-411c-c4c1-8f2f1e1d1608"
      },
      "source": [
        "# Let's now run the training again - we should be getting the same result as \n",
        "# above. \n",
        "params = training_loop_auto(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0, 0.0], requires_grad=True), # requires_grad set to true!\n",
        "    t_u = t_un,\n",
        "    t_c = t_c\n",
        "    )\n",
        "\n",
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 500, Loss: 7.8601155281066895, Grad: tensor([-0.2252,  1.2748]), Params: tensor([ 4.0443, -9.8133], requires_grad=True)\n",
            "Epoch: 1000, Loss: 3.828537940979004, Grad: tensor([-0.0962,  0.5448]), Params: tensor([  4.8021, -14.1031], requires_grad=True)\n",
            "Epoch: 1500, Loss: 3.092191219329834, Grad: tensor([-0.0411,  0.2328]), Params: tensor([  5.1260, -15.9365], requires_grad=True)\n",
            "Epoch: 2000, Loss: 2.9576973915100098, Grad: tensor([-0.0176,  0.0995]), Params: tensor([  5.2644, -16.7200], requires_grad=True)\n",
            "Epoch: 2500, Loss: 2.933133840560913, Grad: tensor([-0.0075,  0.0425]), Params: tensor([  5.3236, -17.0549], requires_grad=True)\n",
            "Epoch: 3000, Loss: 2.9286482334136963, Grad: tensor([-0.0032,  0.0182]), Params: tensor([  5.3489, -17.1980], requires_grad=True)\n",
            "Epoch: 3500, Loss: 2.9278297424316406, Grad: tensor([-0.0014,  0.0078]), Params: tensor([  5.3597, -17.2591], requires_grad=True)\n",
            "Epoch: 4000, Loss: 2.9276793003082275, Grad: tensor([-0.0006,  0.0033]), Params: tensor([  5.3643, -17.2853], requires_grad=True)\n",
            "Epoch: 4500, Loss: 2.92765212059021, Grad: tensor([-0.0003,  0.0014]), Params: tensor([  5.3662, -17.2964], requires_grad=True)\n",
            "Epoch: 5000, Loss: 2.9276468753814697, Grad: tensor([-9.7513e-05,  6.1291e-04]), Params: tensor([  5.3671, -17.3012], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FMp94mYbx_6",
        "colab_type": "text"
      },
      "source": [
        "Looks like it's worked correctly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBp9KoqDd-zI",
        "colab_type": "text"
      },
      "source": [
        "### Optimisers\n",
        "\n",
        "In the example above we have used *vanilla* gradient descent, but PyTorch makes many different optimiser available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVVanBdBa7ed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b507d467-6ebd-453f-c61e-f35d535c1aca"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "dir(optim)[1:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adadelta',\n",
              " 'Adagrad',\n",
              " 'Adam',\n",
              " 'AdamW',\n",
              " 'Adamax',\n",
              " 'LBFGS',\n",
              " 'Optimizer',\n",
              " 'RMSprop',\n",
              " 'Rprop']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHHnFw4eQsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's use this in our training loop\n",
        "def training_loop_optim(n_epochs, optimizer, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    t_p = model(t_u, *params) # forward pass\n",
        "    loss = loss_fn(t_p, t_c) # calculate loss\n",
        "\n",
        "    optimizer.zero_grad() # reset gradient\n",
        "    loss.backward() # calculate gradient\n",
        "    optimizer.step() # update params\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f'Epoch: {epoch}, Loss: {loss}, Grad: {params.grad}, Params: {params}')\n",
        "    \n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqq7TfA6gVpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "3f65deea-c1e7-4330-ea32-6a1abc66e48b"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True) # requires_grad set to true!\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "params = training_loop_optim(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = params, # need to be the same object as defined above\n",
        "    t_u = t_un,\n",
        "    t_c = t_c\n",
        "    )\n",
        "\n",
        "params "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 500, Loss: 7.8601179122924805, Grad: tensor([-0.2252,  1.2748]), Params: tensor([ 4.0443, -9.8133], requires_grad=True)\n",
            "Epoch: 1000, Loss: 3.828537940979004, Grad: tensor([-0.0962,  0.5448]), Params: tensor([  4.8021, -14.1031], requires_grad=True)\n",
            "Epoch: 1500, Loss: 3.092191219329834, Grad: tensor([-0.0411,  0.2328]), Params: tensor([  5.1260, -15.9365], requires_grad=True)\n",
            "Epoch: 2000, Loss: 2.9576973915100098, Grad: tensor([-0.0176,  0.0995]), Params: tensor([  5.2644, -16.7200], requires_grad=True)\n",
            "Epoch: 2500, Loss: 2.933133840560913, Grad: tensor([-0.0075,  0.0425]), Params: tensor([  5.3236, -17.0549], requires_grad=True)\n",
            "Epoch: 3000, Loss: 2.9286482334136963, Grad: tensor([-0.0032,  0.0182]), Params: tensor([  5.3489, -17.1980], requires_grad=True)\n",
            "Epoch: 3500, Loss: 2.9278297424316406, Grad: tensor([-0.0014,  0.0078]), Params: tensor([  5.3597, -17.2591], requires_grad=True)\n",
            "Epoch: 4000, Loss: 2.927680253982544, Grad: tensor([-0.0006,  0.0033]), Params: tensor([  5.3643, -17.2853], requires_grad=True)\n",
            "Epoch: 4500, Loss: 2.9276506900787354, Grad: tensor([-0.0002,  0.0014]), Params: tensor([  5.3662, -17.2964], requires_grad=True)\n",
            "Epoch: 5000, Loss: 2.927647590637207, Grad: tensor([-0.0001,  0.0006]), Params: tensor([  5.3671, -17.3012], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMFyyi-Zh4F3",
        "colab_type": "text"
      },
      "source": [
        "We can swap the optimiser for something more sophisticated like `Adam` which will also not care so much about the scaling of the inputs. To show that `Adam` is better, we set the number of epochs to 2000 and see if we get the same results. We can also use a bigger learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAJdr7eShm-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "37af8056-c204-450a-cc0a-722477102bce"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True) # requires_grad set to true!\n",
        "learning_rate = 1e-1\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "params = training_loop_optim(\n",
        "    n_epochs = 2000,\n",
        "    optimizer = optimizer,\n",
        "    params = params, # need to be the same object as defined above\n",
        "    t_u = t_u,\n",
        "    t_c = t_c\n",
        "    )\n",
        "\n",
        "params "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 500, Loss: 7.612902641296387, Grad: tensor([-1.1790,  1.2604]), Params: tensor([  0.4081, -10.0095], requires_grad=True)\n",
            "Epoch: 1000, Loss: 3.086700201034546, Grad: tensor([-0.2160,  0.2322]), Params: tensor([  0.5131, -15.9629], requires_grad=True)\n",
            "Epoch: 1500, Loss: 2.9285781383514404, Grad: tensor([-0.0167,  0.0178]), Params: tensor([  0.5350, -17.2022], requires_grad=True)\n",
            "Epoch: 2000, Loss: 2.9276459217071533, Grad: tensor([-0.0001,  0.0005]), Params: tensor([  0.5367, -17.3021], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0.5367, -17.3021], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy4RIkQdkFOn",
        "colab_type": "text"
      },
      "source": [
        "## Splitting datasets and autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2pli8n-qg_b",
        "colab_type": "text"
      },
      "source": [
        "We should evaluate the model both on the training and validation sets. The *training loss* tells us if the model has the capacity to approximate the underlying function: if this loss stops falling, then the model is probably too simple. The *validation loss* tells us whether the model is able to generalise, i.e. we're not overfitting it to the training data. If we are, a simpler model could actually be a better choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Zq5UQ9juJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6cc94b92-007a-412e-a35e-530c9b77ebc6"
      },
      "source": [
        "# We can split the data into training and validation sets using the 'randperm'\n",
        "# function\n",
        "\n",
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "print(n_val)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "print(train_indices, val_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "tensor([ 9,  0, 10,  5,  4,  7,  8,  6,  1]) tensor([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_uIbbdhj9jY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwSx9-HTxh1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVk1D6xcxnS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's now rewrite the training loop function. Note that it doesn't change that\n",
        "# much. We simply add the calculation of the validation loss to monitor how the\n",
        "# model performs on that\n",
        "def training_loop_val(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    train_t_p = model(train_t_u, *params) # forward pass\n",
        "    train_loss = loss_fn(train_t_p, train_t_c) # calculate loss\n",
        "\n",
        "    val_t_p = model(val_t_u, *params)\n",
        "    val_loss = loss_fn(val_t_p, val_t_c) # we do not do val_loss.backward() as we're not training on the validation set\n",
        "\n",
        "    optimizer.zero_grad() # reset the gradient\n",
        "    train_loss.backward() # calculate gradient\n",
        "    optimizer.step() # update parameters\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f'Epoch: {epoch}, Training loss: {train_loss}, Validation loss: {val_loss}')\n",
        "    \n",
        "  return params    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fslA3bqMzTBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "6db7d2cb-0f43-4898-c883-92c292b5d9fd"
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD(params = [params], lr = learning_rate)\n",
        "\n",
        "params = training_loop_val(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    train_t_u = train_t_un,\n",
        "    train_t_c = train_t_c,\n",
        "    val_t_u = val_t_un,\n",
        "    val_t_c = val_t_c\n",
        ")\n",
        "\n",
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 500, Training loss: 7.51862907409668, Validation loss: 29.44275665283203\n",
            "Epoch: 1000, Training loss: 3.979889392852783, Validation loss: 13.96703052520752\n",
            "Epoch: 1500, Training loss: 3.195734977722168, Validation loss: 8.71289348602295\n",
            "Epoch: 2000, Training loss: 3.021970510482788, Validation loss: 6.689552307128906\n",
            "Epoch: 2500, Training loss: 2.983468532562256, Validation loss: 5.836835861206055\n",
            "Epoch: 3000, Training loss: 2.974938154220581, Validation loss: 5.4575324058532715\n",
            "Epoch: 3500, Training loss: 2.9730446338653564, Validation loss: 5.283868789672852\n",
            "Epoch: 4000, Training loss: 2.9726269245147705, Validation loss: 5.203215599060059\n",
            "Epoch: 4500, Training loss: 2.972532272338867, Validation loss: 5.165488243103027\n",
            "Epoch: 5000, Training loss: 2.9725141525268555, Validation loss: 5.147782325744629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.0381, -15.9977], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwvc94lE2jlG",
        "colab_type": "text"
      },
      "source": [
        "We can see that both the training loss and the validation loss are falling, which means the model has the capacity to fit the underlying function well, as well as the ability to generalise (note that we're validating on just two observations, but this is a simple problem)\n",
        "\n",
        "Finally, we note that while we call no `backward()` on the validation loss, PyTorch still builds the computational graph for this tensor, which could have an impact on performance for very large model. We can therefore modify the training loop to prevent this from happening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h05G8SIk1f94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_loop_val+optimised(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    train_t_p = model(train_t_u, *params) # forward pass\n",
        "    train_loss = loss_fn(train_t_p, train_t_c) # calculate loss\n",
        "\n",
        "    with torch.no_grad:\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p, val_t_c)\n",
        "      assert val_loss.requires_grad == False # to make sure autograd is not used here\n",
        "\n",
        "    optimizer.zero_grad() # reset the gradient\n",
        "    train_loss.backward() # calculate gradient\n",
        "    optimizer.step() # update parameters\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f'Epoch: {epoch}, Training loss: {train_loss}, Validation loss: {val_loss}')\n",
        "    \n",
        "  return params   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZSHuQZb8F56",
        "colab_type": "text"
      },
      "source": [
        "## Exercise\n",
        "Assume the model is now `w2 * t_u ** 2 + w1 * t_u + b`. What needs to change and what stays the same?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8uxeMy38TJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only thing that needs to change is the actual model, the loss function will be\n",
        "# the same\n",
        "def new_model(t_u, w2, w1, b):\n",
        "  return w2 * t_u ** 2 + w1 * t_u + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U20iHJYy9sFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same for the inputs and validation sets, while the params will be three\n",
        "# Let's rewrite the training loop for practice\n",
        "\n",
        "def new_training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    train_t_p = new_model(train_t_u, *params) # forward pass\n",
        "    train_loss = loss_fn(train_t_p, train_t_c) # calculate training loss\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_t_p = new_model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p, val_t_c)\n",
        "      assert val_loss.requires_grad == False\n",
        "\n",
        "    optimizer.zero_grad() # reset the gradient\n",
        "    train_loss.backward() # calculate the gradient\n",
        "    optimizer.step() # update the parameters\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(f'Epoch: {epoch}, Train loss: {train_loss}, Val loss: {val_loss}')\n",
        "  \n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxLB8-Br-FE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "3d7c7b80-51b8-40d4-8751-fa1b5669cb21"
      },
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-1\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "params = new_training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer = optimizer,\n",
        "    params = params,\n",
        "    train_t_u = train_t_u,\n",
        "    train_t_c = train_t_c,\n",
        "    val_t_u = val_t_u,\n",
        "    val_t_c = val_t_c\n",
        ")\n",
        "\n",
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 500, Train loss: 4.948853015899658, Val loss: 2.371265411376953\n",
            "Epoch: 1000, Train loss: 3.1130123138427734, Val loss: 5.368891716003418\n",
            "Epoch: 1500, Train loss: 2.4230473041534424, Val loss: 11.829986572265625\n",
            "Epoch: 2000, Train loss: 2.2883412837982178, Val loss: 16.39069366455078\n",
            "Epoch: 2500, Train loss: 2.2722256183624268, Val loss: 18.053081512451172\n",
            "Epoch: 3000, Train loss: 2.2666101455688477, Val loss: 18.296436309814453\n",
            "Epoch: 3500, Train loss: 2.260054349899292, Val loss: 18.15570068359375\n",
            "Epoch: 4000, Train loss: 2.251817464828491, Val loss: 17.920482635498047\n",
            "Epoch: 4500, Train loss: 2.241586446762085, Val loss: 17.62169075012207\n",
            "Epoch: 5000, Train loss: 2.229031562805176, Val loss: 17.249906539916992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0074, -0.1696, -2.0454], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EJE_qyADgLA",
        "colab_type": "text"
      },
      "source": [
        "The performance is worse in this case, as we're trying to fit a non-linear model to linear data. Essentially, there's too many parameters, so while the training loss function starts small and converges fast, the validation loss function grows and never really falls. This indicates overfitting, and this model is not able to generalise."
      ]
    }
  ]
}